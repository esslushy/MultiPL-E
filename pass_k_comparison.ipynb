{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pass_k import estimator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_across_completion(completion):\n",
    "    n = len(completion[\"statuses\"])\n",
    "    c = 0\n",
    "    for status, exit_code in zip(completion[\"statuses\"], completion[\"exit_codes\"]):\n",
    "         if status == \"OK\" and exit_code == 0:\n",
    "             c+=1\n",
    "    return estimator(n, c, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/Claire Schlesinger/.cache/huggingface/datasets/bigcode___parquet/bigcode--MultiPL-E-completions-14a614b6817a435b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (C:/Users/Claire Schlesinger/.cache/huggingface/datasets/bigcode___parquet/bigcode--MultiPL-E-completions-14a614b6817a435b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems</th>\n",
       "      <th>chatgpt pass@1</th>\n",
       "      <th>starcoder pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval_0_has_close_elements</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval_100_make_a_pile</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval_101_words_string</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval_102_choose_num</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval_103_rounded_avg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         problems  chatgpt pass@1  starcoder pass@1\n",
       "0  HumanEval_0_has_close_elements             1.0             0.945\n",
       "1       HumanEval_100_make_a_pile             0.0             0.000\n",
       "2      HumanEval_101_words_string             0.4             0.000\n",
       "3        HumanEval_102_choose_num             1.0             0.010\n",
       "4       HumanEval_103_rounded_avg             1.0             0.155"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_completions = load_dataset(\"bigcode/MultiPL-E-completions\", split=f\"humaneval.py.chatgpt.0.2.reworded\")\n",
    "starcoder_completions = load_dataset(\"bigcode/MultiPL-E-completions\", split=f\"humaneval.py.bigcode_15b_1000m.0.2.reworded\")\n",
    "\n",
    "chatgpt_df = pd.DataFrame({\n",
    "    \"problems\" : chatgpt_completions[\"problem\"], \n",
    "    \"chatgpt pass@1\" : [estimate_across_completion(completion) for completion in chatgpt_completions]\n",
    "})\n",
    "    \n",
    "starcoder_df = pd.DataFrame({\n",
    "    \"problems\" : chatgpt_completions[\"problem\"], \n",
    "    \"starcoder pass@1\" : [estimate_across_completion(completion) for completion in starcoder_completions]\n",
    "})\n",
    "\n",
    "eval_df = chatgpt_df.merge(starcoder_df, on=\"problems\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems</th>\n",
       "      <th>chatgpt pass@1</th>\n",
       "      <th>starcoder pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval_100_make_a_pile</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HumanEval_106_f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HumanEval_108_count_nums</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HumanEval_10_make_palindrome</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HumanEval_113_odd_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HumanEval_119_match_parens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HumanEval_125_split_words</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HumanEval_127_intersection</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HumanEval_129_minPath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HumanEval_130_tri</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HumanEval_132_is_nested</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HumanEval_133_sum_squares</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>HumanEval_135_can_arrange</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>HumanEval_140_fix_spaces</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>HumanEval_141_file_name_check</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>HumanEval_145_order_by_points</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HumanEval_151_double_the_difference</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>HumanEval_160_do_algebra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>HumanEval_162_string_to_md5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>HumanEval_163_generate_integers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>HumanEval_39_prime_fib</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HumanEval_41_car_race_collision</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>HumanEval_84_solve</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>HumanEval_93_encode</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                problems  chatgpt pass@1  starcoder pass@1\n",
       "1              HumanEval_100_make_a_pile             0.0               0.0\n",
       "7                        HumanEval_106_f             0.0               0.0\n",
       "9               HumanEval_108_count_nums             0.0               0.0\n",
       "11          HumanEval_10_make_palindrome             0.0               0.0\n",
       "15               HumanEval_113_odd_count             0.0               0.0\n",
       "21            HumanEval_119_match_parens             0.0               0.0\n",
       "28             HumanEval_125_split_words             0.0               0.0\n",
       "30            HumanEval_127_intersection             0.0               0.0\n",
       "32                 HumanEval_129_minPath             0.0               0.0\n",
       "34                     HumanEval_130_tri             0.0               0.0\n",
       "36               HumanEval_132_is_nested             0.0               0.0\n",
       "37             HumanEval_133_sum_squares             0.0               0.0\n",
       "39             HumanEval_135_can_arrange             0.0               0.0\n",
       "45              HumanEval_140_fix_spaces             0.0               0.0\n",
       "46         HumanEval_141_file_name_check             0.0               0.0\n",
       "50         HumanEval_145_order_by_points             0.0               0.0\n",
       "57   HumanEval_151_double_the_difference             0.0               0.0\n",
       "67              HumanEval_160_do_algebra             0.0               0.0\n",
       "69           HumanEval_162_string_to_md5             0.0               0.0\n",
       "70       HumanEval_163_generate_integers             0.0               0.0\n",
       "94                HumanEval_39_prime_fib             0.0               0.0\n",
       "97       HumanEval_41_car_race_collision             0.0               0.0\n",
       "143                   HumanEval_84_solve             0.0               0.0\n",
       "153                  HumanEval_93_encode             0.0               0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.loc[(eval_df[\"chatgpt pass@1\"] == 0) & (eval_df[\"starcoder pass@1\"] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems</th>\n",
       "      <th>chatgpt pass@1</th>\n",
       "      <th>starcoder pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval_0_has_close_elements</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval_101_words_string</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval_102_choose_num</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval_103_rounded_avg</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HumanEval_104_unique_digits</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>HumanEval_95_check_dict_case</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>HumanEval_96_count_up_to</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>HumanEval_98_count_upper</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>HumanEval_99_closest_integer</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>HumanEval_9_rolling_max</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           problems  chatgpt pass@1  starcoder pass@1\n",
       "0    HumanEval_0_has_close_elements            1.00             0.945\n",
       "2        HumanEval_101_words_string            0.40             0.000\n",
       "3          HumanEval_102_choose_num            1.00             0.010\n",
       "4         HumanEval_103_rounded_avg            1.00             0.155\n",
       "5       HumanEval_104_unique_digits            1.00             0.135\n",
       "..                              ...             ...               ...\n",
       "155    HumanEval_95_check_dict_case            0.65             0.640\n",
       "156        HumanEval_96_count_up_to            0.35             0.005\n",
       "158        HumanEval_98_count_upper            1.00             0.375\n",
       "159    HumanEval_99_closest_integer            1.00             0.000\n",
       "160         HumanEval_9_rolling_max            1.00             0.090\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.loc[(eval_df[\"chatgpt pass@1\"] > eval_df[\"starcoder pass@1\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problems</th>\n",
       "      <th>chatgpt pass@1</th>\n",
       "      <th>starcoder pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HumanEval_109_move_one_ball</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HumanEval_114_minSubArraySum</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HumanEval_120_maximum</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HumanEval_121_solution</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HumanEval_122_add_elements</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HumanEval_137_compare_one</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>HumanEval_26_remove_duplicates</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>HumanEval_36_fizz_buzz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>HumanEval_46_fib4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>HumanEval_54_same_chars</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>HumanEval_67_fruit_distribution</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>HumanEval_87_get_row</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>HumanEval_97_multiply</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            problems  chatgpt pass@1  starcoder pass@1\n",
       "10       HumanEval_109_move_one_ball             0.0             0.110\n",
       "16      HumanEval_114_minSubArraySum             0.1             0.240\n",
       "23             HumanEval_120_maximum             0.0             0.005\n",
       "24            HumanEval_121_solution             0.0             0.950\n",
       "25        HumanEval_122_add_elements             0.0             0.155\n",
       "41         HumanEval_137_compare_one             0.0             0.015\n",
       "82    HumanEval_26_remove_duplicates             0.0             0.160\n",
       "92            HumanEval_36_fizz_buzz             0.0             0.005\n",
       "102                HumanEval_46_fib4             0.0             0.965\n",
       "110          HumanEval_54_same_chars             0.1             0.475\n",
       "124  HumanEval_67_fruit_distribution             0.1             0.540\n",
       "146             HumanEval_87_get_row             0.0             0.895\n",
       "157            HumanEval_97_multiply             0.0             0.305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.loc[(eval_df[\"chatgpt pass@1\"] < eval_df[\"starcoder pass@1\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_df = eval_df.loc[(eval_df[\"chatgpt pass@1\"] - eval_df[\"starcoder pass@1\"] >= 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_df.to_csv(\"chatgpt_significant_outperform.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HumanEval_101_words_string', 'HumanEval_102_choose_num',\n",
       "       'HumanEval_103_rounded_avg', 'HumanEval_104_unique_digits',\n",
       "       'HumanEval_105_by_length', 'HumanEval_110_exchange',\n",
       "       'HumanEval_111_histogram', 'HumanEval_112_reverse_delete',\n",
       "       'HumanEval_115_max_fill', 'HumanEval_117_select_words',\n",
       "       'HumanEval_123_get_odd_collatz', 'HumanEval_124_valid_date',\n",
       "       'HumanEval_126_is_sorted', 'HumanEval_131_digits',\n",
       "       'HumanEval_136_largest_smallest_integers',\n",
       "       'HumanEval_138_is_equal_to_sum_even',\n",
       "       'HumanEval_139_special_factorial', 'HumanEval_142_sum_squares',\n",
       "       'HumanEval_143_words_in_sentence', 'HumanEval_144_simplify',\n",
       "       'HumanEval_146_specialFilter', 'HumanEval_147_get_max_triples',\n",
       "       'HumanEval_148_bf', 'HumanEval_149_sorted_list_sum',\n",
       "       'HumanEval_14_all_prefixes', 'HumanEval_150_x_or_y',\n",
       "       'HumanEval_153_Strongest_Extension',\n",
       "       'HumanEval_154_cycpattern_check', 'HumanEval_155_even_odd_count',\n",
       "       'HumanEval_156_int_to_mini_roman',\n",
       "       'HumanEval_157_right_angle_triangle', 'HumanEval_158_find_max',\n",
       "       'HumanEval_159_eat', 'HumanEval_161_solve',\n",
       "       'HumanEval_16_count_distinct_characters',\n",
       "       'HumanEval_17_parse_music', 'HumanEval_18_how_many_times',\n",
       "       'HumanEval_19_sort_numbers', 'HumanEval_1_separate_paren_groups',\n",
       "       'HumanEval_20_find_closest_elements',\n",
       "       'HumanEval_21_rescale_to_unit', 'HumanEval_24_largest_divisor',\n",
       "       'HumanEval_25_factorize', 'HumanEval_2_truncate_number',\n",
       "       'HumanEval_30_get_positive', 'HumanEval_31_is_prime',\n",
       "       'HumanEval_33_sort_third', 'HumanEval_37_sort_even',\n",
       "       'HumanEval_40_triples_sum_to_zero',\n",
       "       'HumanEval_43_pairs_sum_to_zero',\n",
       "       'HumanEval_4_mean_absolute_deviation',\n",
       "       'HumanEval_51_remove_vowels', 'HumanEval_59_largest_prime_factor',\n",
       "       'HumanEval_5_intersperse', 'HumanEval_62_derivative',\n",
       "       'HumanEval_64_vowels_count', 'HumanEval_65_circular_shift',\n",
       "       'HumanEval_68_pluck', 'HumanEval_69_search',\n",
       "       'HumanEval_6_parse_nested_parens',\n",
       "       'HumanEval_70_strange_sort_list', 'HumanEval_71_triangle_area',\n",
       "       'HumanEval_72_will_it_fly', 'HumanEval_73_smallest_change',\n",
       "       'HumanEval_74_total_match', 'HumanEval_76_is_simple_power',\n",
       "       'HumanEval_77_iscube', 'HumanEval_78_hex_key',\n",
       "       'HumanEval_79_decimal_to_binary', 'HumanEval_80_is_happy',\n",
       "       'HumanEval_81_numerical_letter_grade', 'HumanEval_82_prime_length',\n",
       "       'HumanEval_85_add', 'HumanEval_86_anti_shuffle',\n",
       "       'HumanEval_88_sort_array', 'HumanEval_89_encrypt',\n",
       "       'HumanEval_8_sum_product', 'HumanEval_90_next_smallest',\n",
       "       'HumanEval_91_is_bored', 'HumanEval_92_any_int',\n",
       "       'HumanEval_94_skjkasdkd', 'HumanEval_96_count_up_to',\n",
       "       'HumanEval_98_count_upper', 'HumanEval_99_closest_integer',\n",
       "       'HumanEval_9_rolling_max'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_df[\"problems\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
